{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19454135-8064-446b-96fa-f056f1ba3b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:34:24.832136Z",
     "iopub.status.busy": "2024-12-16T15:34:24.831906Z",
     "iopub.status.idle": "2024-12-16T15:35:04.127487Z",
     "shell.execute_reply": "2024-12-16T15:35:04.126849Z",
     "shell.execute_reply.started": "2024-12-16T15:34:24.832118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Channels:\n",
      " - pytorch\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/notebook\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cpu\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge\n",
      "    filelock-3.16.1            |     pyhd8ed1ab_1          17 KB  conda-forge\n",
      "    gmpy2-2.1.5                |  py311h0f6cedb_3         198 KB  conda-forge\n",
      "    libtorch-2.5.1             |cpu_generic_h1b269f6_6        51.0 MB  conda-forge\n",
      "    mpc-1.3.1                  |       h24ddda3_1         114 KB  conda-forge\n",
      "    mpmath-1.3.0               |     pyhd8ed1ab_1         429 KB  conda-forge\n",
      "    nomkl-1.0                  |       h5ca1d4c_0           4 KB  conda-forge\n",
      "    pytorch-2.5.1              |cpu_generic_py311h2edd984_6        36.1 MB  conda-forge\n",
      "    pytorch-cpu-2.5.1          |cpu_generic_hd752803_6          24 KB  conda-forge\n",
      "    sleef-3.7                  |       h1b44611_2         1.8 MB  conda-forge\n",
      "    sympy-1.13.3               | pypyh2585a3b_103         4.4 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        94.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  filelock           conda-forge/noarch::filelock-3.16.1-pyhd8ed1ab_1 \n",
      "  gmpy2              conda-forge/linux-64::gmpy2-2.1.5-py311h0f6cedb_3 \n",
      "  libtorch           conda-forge/linux-64::libtorch-2.5.1-cpu_generic_h1b269f6_6 \n",
      "  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n",
      "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
      "  nomkl              conda-forge/noarch::nomkl-1.0-h5ca1d4c_0 \n",
      "  pytorch            conda-forge/linux-64::pytorch-2.5.1-cpu_generic_py311h2edd984_6 \n",
      "  pytorch-cpu        conda-forge/linux-64::pytorch-cpu-2.5.1-cpu_generic_hd752803_6 \n",
      "  sleef              conda-forge/linux-64::sleef-3.7-h1b44611_2 \n",
      "  sympy              conda-forge/noarch::sympy-1.13.3-pypyh2585a3b_103 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2024.8.30-hbcca054_0 --> 2024.12.14-hbcca054_0 \n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -yq pytorch-cpu -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af575dfd-f7a3-4da9-88d6-7b38e8b148f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:39:01.733650Z",
     "iopub.status.busy": "2024-12-16T15:39:01.733476Z",
     "iopub.status.idle": "2024-12-16T15:39:03.297395Z",
     "shell.execute_reply": "2024-12-16T15:39:03.296827Z",
     "shell.execute_reply.started": "2024-12-16T15:39:01.733631Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This notebook trains and evaluates a convolutional neural network for wavelet analysis.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from copy import deepcopy\n",
    "\n",
    "from model import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9039fb-891e-44db-9160-16cdfcc5d9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:39:03.299805Z",
     "iopub.status.busy": "2024-12-16T15:39:03.299608Z",
     "iopub.status.idle": "2024-12-16T15:39:10.090339Z",
     "shell.execute_reply": "2024-12-16T15:39:10.089893Z",
     "shell.execute_reply.started": "2024-12-16T15:39:03.299791Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"ebs\", \"exo\", \"flares\", \"rot\"]\n",
    "cat = pd.DataFrame([], columns=[\"TIC\", \"sector\", *cols, \"wavelet\"])\n",
    "cat.index.name = \"filename\"\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    for s in os.listdir(f\"wavelets/tess-{col}\"):\n",
    "        if s not in cat.index:\n",
    "            wav = np.load(f\"wavelets/tess-{col}/{s}\")\n",
    "            cat.loc[s] = [int(s[24:40]), int(s[19:23]), *([0]*len(cols)), wav/wav.max()]\n",
    "        cat.loc[s, col] = 1\n",
    "\n",
    "cat = cat.reset_index().set_index([\"TIC\", \"sector\"]).sort_index()\n",
    "cat[cols] = cat[cols].div(cat[cols].sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976806b-b46f-4f65-845f-5af9fc019bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct list of values \"{tic}_{s}\" for each sector of each TIC ID\n",
    "# unused for now but this might be useful later.\n",
    "# ebs = pd.read_csv(\"catalogs/tess-ebs.csv\")\n",
    "# ebs[\"sectors\"] = ebs[\"sectors\"].apply(lambda x: list(map(int, x.strip(\"[]\").split(\", \"))))\n",
    "# ids = [f\"{row['ID']}_{s}\" for _, row in ebs.iterrows() for s in row['sectors']]\n",
    "# len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840decba-f3eb-428d-b23b-b15fd1481652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:39:10.091239Z",
     "iopub.status.busy": "2024-12-16T15:39:10.091099Z",
     "iopub.status.idle": "2024-12-16T15:39:10.095087Z",
     "shell.execute_reply": "2024-12-16T15:39:10.094681Z",
     "shell.execute_reply.started": "2024-12-16T15:39:10.091223Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set global parameters based on command line input\n",
    "RUN_NUMBER = 0 # which channels selection to use\n",
    "BATCH_SIZE = 100\n",
    "PATIENCE = 30\n",
    "MAX_EPOCHS = 500\n",
    "RUN_NAME = \"batchnorm1\"\n",
    "\n",
    "MODEL_NAME = f\"{RUN_NAME}_{RUN_NUMBER}\"\n",
    "\n",
    "# Channel configurations\n",
    "channels = {\n",
    "    0: [8, 16, 32],\n",
    "    1: [16, 32, 64],\n",
    "    2: [32, 64, 128],\n",
    "    3: [64, 128, 256]\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "for folder in ['models', 'plots', 'losses', 'output']:\n",
    "    os.makedirs(os.path.join(MODEL_NAME, folder), exist_ok=True)\n",
    "\n",
    "selected_channels = channels[RUN_NUMBER]\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e180490c-b209-4655-818d-c6a2873e5e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:39:10.095987Z",
     "iopub.status.busy": "2024-12-16T15:39:10.095788Z",
     "iopub.status.idle": "2024-12-16T15:39:10.106373Z",
     "shell.execute_reply": "2024-12-16T15:39:10.105900Z",
     "shell.execute_reply.started": "2024-12-16T15:39:10.095968Z"
    }
   },
   "outputs": [],
   "source": [
    "class WaveletDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for loading wavelet data from files.\n",
    "\n",
    "    This class is responsible for loading wavelet data and corresponding labels\n",
    "    from the specified file paths. It supports splitting the data into training,\n",
    "    validation, and test sets.\n",
    "\n",
    "    Attributes:\n",
    "        data_frame (np.ndarray): Array containing the wavelet data.\n",
    "        labels (np.ndarray): Array containing the scaled labels.\n",
    "    \"\"\"    \n",
    "    def __init__(self, data, mode, split=[0.8, 0.1, 0.1]):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): the input and output data.\n",
    "            mode (str): Mode to load ('train', 'val', or 'test').\n",
    "            split (list): train, validation, and test split fractions.\n",
    "        \"\"\"\n",
    "        ftrain, fval, ftest = [s/sum(split) for s in split]\n",
    "        i_train = int(ftrain * len(data))\n",
    "        i_val = int((ftrain + fval) * len(data))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            df = data.iloc[:i_train]\n",
    "        elif mode == \"val\":\n",
    "            df = data.iloc[i_train:i_val]\n",
    "        elif mode == \"test\":\n",
    "            df = data.iloc[i_val:]\n",
    "            \n",
    "        self.features = df[\"wavelet\"].values\n",
    "        self.labels = df[[\"ebs\", \"exo\", \"flares\", \"rot\"]].values\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieve a single sample and its corresponding label.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the sample data (torch.Tensor) and the \n",
    "                   corresponding label (torch.Tensor).\n",
    "        \"\"\"\n",
    "        X = self.features[idx].astype('float32')\n",
    "        X = torch.unsqueeze(torch.tensor(X), 0)\n",
    "        label = torch.tensor(self.labels[idx].astype('float32'))\n",
    "        return X, label\n",
    "        \n",
    "\n",
    "def train(model, device, train_loader, val_loader, patience, max_epochs, model_name=\"cnn\"):\n",
    "    \"\"\"Train the neural network for the specified number of epochs.\n",
    "\n",
    "    This function orchestrates the training loop, updating model weights based on\n",
    "    the training data, validating the model on a validation set, and handling\n",
    "    early stopping based on validation loss.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        device (torch.device): The device (CPU or GPU) on which to perform training.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        patience (int): Early stopping patience.\n",
    "        max_epochs (int): Maximum number of training iterations.\n",
    "        model_name (str): The name of the model, used for saving the trained weights.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best model weights, training losses, and validation losses.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.7, patience=3)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    min_loss = float('inf')\n",
    "    early_stopping_count = 0\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss = train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        val_loss = test(model, device, val_loader, epoch, MODEL_NAME, mode=\"Validation\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            early_stopping_count = 0\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            early_stopping_count += 1\n",
    "            print(f\"        Early Stopping count: {early_stopping_count}/{patience}\")\n",
    "            if early_stopping_count == patience:\n",
    "                print(f\"\\nEarly Stopping. Best Epoch: {epoch - patience} with loss {min_loss:.4f}.\")\n",
    "                break\n",
    "\n",
    "    torch.save(best_weights, f\"{model_name}/models/{model_name}.pt\")\n",
    "    return best_weights, train_losses, val_losses\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"Train the model for one epoch.\n",
    "\n",
    "    This function processes each batch of training data, computes the loss,\n",
    "    and updates the model weights accordingly.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        device (torch.device): The device (CPU or GPU) for training.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for weight updates.\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    ndata = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        ndata += len(data)\n",
    "        #if (batch_idx * len(data)) % 10000 == 0:\n",
    "        print(\n",
    "            f'Train Epoch: {epoch:3d} [{ndata:6d}/{len(train_loader.dataset)}'\n",
    "            f' ({100*ndata/len(train_loader.dataset):3.0f}%)]\\tLoss: {losses[-1]:.6f}',\n",
    "            end=\"\\r\")\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, epoch=None, model_name=None, mode=\"Validation\"):\n",
    "    \"\"\"Evaluate the model on the test set.\n",
    "\n",
    "    This function assesses the model's performance on a specified dataset\n",
    "    and computes the average loss. It can also generate a plot of predictions\n",
    "    versus true values.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be evaluated.\n",
    "        device (torch.device): The device (CPU or GPU) for evaluation.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        epoch (int, optional): The current epoch number (for labeling purposes).\n",
    "        model_name (str, optional): The name of the model (for labeling purposes).\n",
    "        mode (str, optional): Indicates whether the evaluation is for training, validation, or testing.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    targets, preds = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            targets.extend(target.cpu().numpy())\n",
    "            preds.extend(output.cpu().numpy())\n",
    "            test_loss += loss_function(output, target).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'\\n                     Average {mode} Loss: {test_loss:.4f}')\n",
    "\n",
    "    if mode.lower() == \"test\":\n",
    "        return np.squeeze(preds), np.squeeze(targets), test_loss\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0c7ba2-f9fb-42f6-93cb-51bf7a91f19b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:39:11.622045Z",
     "iopub.status.busy": "2024-12-16T15:39:11.621612Z",
     "iopub.status.idle": "2024-12-16T17:19:35.781238Z",
     "shell.execute_reply": "2024-12-16T17:19:35.780750Z",
     "shell.execute_reply.started": "2024-12-16T15:39:11.622028Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   1 [  5559/5559 (100%)]\tLoss: 1.342283\n",
      "                     Average Validation Loss: 1.3629\n",
      "Train Epoch:   2 [  5559/5559 (100%)]\tLoss: 1.304236\n",
      "                     Average Validation Loss: 1.3080\n",
      "Train Epoch:   3 [  5559/5559 (100%)]\tLoss: 1.277129\n",
      "                     Average Validation Loss: 1.2868\n",
      "Train Epoch:   4 [  5559/5559 (100%)]\tLoss: 1.247453\n",
      "                     Average Validation Loss: 1.2695\n",
      "Train Epoch:   5 [  5559/5559 (100%)]\tLoss: 1.243188\n",
      "                     Average Validation Loss: 1.2561\n",
      "Train Epoch:   6 [  5559/5559 (100%)]\tLoss: 1.222586\n",
      "                     Average Validation Loss: 1.2430\n",
      "Train Epoch:   7 [  5559/5559 (100%)]\tLoss: 1.228663\n",
      "                     Average Validation Loss: 1.2325\n",
      "Train Epoch:   8 [  5559/5559 (100%)]\tLoss: 1.200608\n",
      "                     Average Validation Loss: 1.2246\n",
      "Train Epoch:   9 [  5559/5559 (100%)]\tLoss: 1.204710\n",
      "                     Average Validation Loss: 1.2150\n",
      "Train Epoch:  10 [  5559/5559 (100%)]\tLoss: 1.201417\n",
      "                     Average Validation Loss: 1.2076\n",
      "Train Epoch:  11 [  5559/5559 (100%)]\tLoss: 1.165435\n",
      "                     Average Validation Loss: 1.2011\n",
      "Train Epoch:  12 [  5559/5559 (100%)]\tLoss: 1.167819\n",
      "                     Average Validation Loss: 1.1948\n",
      "Train Epoch:  13 [  5559/5559 (100%)]\tLoss: 1.168428\n",
      "                     Average Validation Loss: 1.1897\n",
      "Train Epoch:  14 [  5559/5559 (100%)]\tLoss: 1.168220\n",
      "                     Average Validation Loss: 1.1839\n",
      "Train Epoch:  15 [  5559/5559 (100%)]\tLoss: 1.160499\n",
      "                     Average Validation Loss: 1.1784\n",
      "Train Epoch:  16 [  5559/5559 (100%)]\tLoss: 1.151342\n",
      "                     Average Validation Loss: 1.1752\n",
      "Train Epoch:  17 [  5559/5559 (100%)]\tLoss: 1.143565\n",
      "                     Average Validation Loss: 1.1711\n",
      "Train Epoch:  18 [  5559/5559 (100%)]\tLoss: 1.126927\n",
      "                     Average Validation Loss: 1.1670\n",
      "Train Epoch:  19 [  5559/5559 (100%)]\tLoss: 1.140168\n",
      "                     Average Validation Loss: 1.1635\n",
      "Train Epoch:  20 [  5559/5559 (100%)]\tLoss: 1.135983\n",
      "                     Average Validation Loss: 1.1583\n",
      "Train Epoch:  21 [  5559/5559 (100%)]\tLoss: 1.126773\n",
      "                     Average Validation Loss: 1.1547\n",
      "Train Epoch:  22 [  5559/5559 (100%)]\tLoss: 1.137509\n",
      "                     Average Validation Loss: 1.1516\n",
      "Train Epoch:  23 [  5559/5559 (100%)]\tLoss: 1.126594\n",
      "                     Average Validation Loss: 1.1469\n",
      "Train Epoch:  24 [  5559/5559 (100%)]\tLoss: 1.107356\n",
      "                     Average Validation Loss: 1.1434\n",
      "Train Epoch:  25 [  5559/5559 (100%)]\tLoss: 1.132857\n",
      "                     Average Validation Loss: 1.1412\n",
      "Train Epoch:  26 [  5559/5559 (100%)]\tLoss: 1.131473\n",
      "                     Average Validation Loss: 1.1390\n",
      "Train Epoch:  27 [  5559/5559 (100%)]\tLoss: 1.123487\n",
      "                     Average Validation Loss: 1.1344\n",
      "Train Epoch:  28 [  5559/5559 (100%)]\tLoss: 1.097712\n",
      "                     Average Validation Loss: 1.1312\n",
      "Train Epoch:  29 [  5559/5559 (100%)]\tLoss: 1.092099\n",
      "                     Average Validation Loss: 1.1287\n",
      "Train Epoch:  30 [  5559/5559 (100%)]\tLoss: 1.101511\n",
      "                     Average Validation Loss: 1.1266\n",
      "Train Epoch:  31 [  5559/5559 (100%)]\tLoss: 1.107922\n",
      "                     Average Validation Loss: 1.1238\n",
      "Train Epoch:  32 [  5559/5559 (100%)]\tLoss: 1.106377\n",
      "                     Average Validation Loss: 1.1215\n",
      "Train Epoch:  33 [  5559/5559 (100%)]\tLoss: 1.106345\n",
      "                     Average Validation Loss: 1.1184\n",
      "Train Epoch:  34 [  5559/5559 (100%)]\tLoss: 1.090791\n",
      "                     Average Validation Loss: 1.1158\n",
      "Train Epoch:  35 [  5559/5559 (100%)]\tLoss: 1.104837\n",
      "                     Average Validation Loss: 1.1132\n",
      "Train Epoch:  36 [  5559/5559 (100%)]\tLoss: 1.083649\n",
      "                     Average Validation Loss: 1.1112\n",
      "Train Epoch:  37 [  5559/5559 (100%)]\tLoss: 1.092678\n",
      "                     Average Validation Loss: 1.1090\n",
      "Train Epoch:  38 [  5559/5559 (100%)]\tLoss: 1.092749\n",
      "                     Average Validation Loss: 1.1072\n",
      "Train Epoch:  39 [  5559/5559 (100%)]\tLoss: 1.068293\n",
      "                     Average Validation Loss: 1.1037\n",
      "Train Epoch:  40 [  5559/5559 (100%)]\tLoss: 1.081007\n",
      "                     Average Validation Loss: 1.1030\n",
      "Train Epoch:  41 [  5559/5559 (100%)]\tLoss: 1.082129\n",
      "                     Average Validation Loss: 1.1011\n",
      "Train Epoch:  42 [  5559/5559 (100%)]\tLoss: 1.065947\n",
      "                     Average Validation Loss: 1.0994\n",
      "Train Epoch:  43 [  5559/5559 (100%)]\tLoss: 1.085369\n",
      "                     Average Validation Loss: 1.0977\n",
      "Train Epoch:  44 [  5559/5559 (100%)]\tLoss: 1.079178\n",
      "                     Average Validation Loss: 1.0953\n",
      "Train Epoch:  45 [  5559/5559 (100%)]\tLoss: 1.059664\n",
      "                     Average Validation Loss: 1.0931\n",
      "Train Epoch:  46 [  5559/5559 (100%)]\tLoss: 1.068405\n",
      "                     Average Validation Loss: 1.0900\n",
      "Train Epoch:  47 [  5559/5559 (100%)]\tLoss: 1.071100\n",
      "                     Average Validation Loss: 1.0892\n",
      "Train Epoch:  48 [  5559/5559 (100%)]\tLoss: 1.066557\n",
      "                     Average Validation Loss: 1.0868\n",
      "Train Epoch:  49 [  5559/5559 (100%)]\tLoss: 1.054389\n",
      "                     Average Validation Loss: 1.0860\n",
      "Train Epoch:  50 [  5559/5559 (100%)]\tLoss: 1.080007\n",
      "                     Average Validation Loss: 1.0836\n",
      "Train Epoch:  51 [  5559/5559 (100%)]\tLoss: 1.074389\n",
      "                     Average Validation Loss: 1.0829\n",
      "Train Epoch:  52 [  5559/5559 (100%)]\tLoss: 1.052593\n",
      "                     Average Validation Loss: 1.0802\n",
      "Train Epoch:  53 [  5559/5559 (100%)]\tLoss: 1.043045\n",
      "                     Average Validation Loss: 1.0789\n",
      "Train Epoch:  54 [  5559/5559 (100%)]\tLoss: 1.063484\n",
      "                     Average Validation Loss: 1.0773\n",
      "Train Epoch:  55 [  5559/5559 (100%)]\tLoss: 1.063916\n",
      "                     Average Validation Loss: 1.0747\n",
      "Train Epoch:  56 [  5559/5559 (100%)]\tLoss: 1.017072\n",
      "                     Average Validation Loss: 1.0747\n",
      "Train Epoch:  57 [  5559/5559 (100%)]\tLoss: 1.053215\n",
      "                     Average Validation Loss: 1.0732\n",
      "Train Epoch:  58 [  5559/5559 (100%)]\tLoss: 1.067256\n",
      "                     Average Validation Loss: 1.0707\n",
      "Train Epoch:  59 [  5559/5559 (100%)]\tLoss: 1.045308\n",
      "                     Average Validation Loss: 1.0688\n",
      "Train Epoch:  60 [  5559/5559 (100%)]\tLoss: 1.026273\n",
      "                     Average Validation Loss: 1.0692\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch:  61 [  5559/5559 (100%)]\tLoss: 1.046032\n",
      "                     Average Validation Loss: 1.0673\n",
      "Train Epoch:  62 [  5559/5559 (100%)]\tLoss: 1.033831\n",
      "                     Average Validation Loss: 1.0656\n",
      "Train Epoch:  63 [  5559/5559 (100%)]\tLoss: 1.037827\n",
      "                     Average Validation Loss: 1.0649\n",
      "Train Epoch:  64 [  5559/5559 (100%)]\tLoss: 1.043472\n",
      "                     Average Validation Loss: 1.0635\n",
      "Train Epoch:  65 [  5559/5559 (100%)]\tLoss: 1.048435\n",
      "                     Average Validation Loss: 1.0625\n",
      "Train Epoch:  66 [  5559/5559 (100%)]\tLoss: 1.034700\n",
      "                     Average Validation Loss: 1.0606\n",
      "Train Epoch:  67 [  5559/5559 (100%)]\tLoss: 1.029310\n",
      "                     Average Validation Loss: 1.0589\n",
      "Train Epoch:  68 [  5559/5559 (100%)]\tLoss: 1.042878\n",
      "                     Average Validation Loss: 1.0577\n",
      "Train Epoch:  69 [  5559/5559 (100%)]\tLoss: 1.030790\n",
      "                     Average Validation Loss: 1.0570\n",
      "Train Epoch:  70 [  5559/5559 (100%)]\tLoss: 1.029583\n",
      "                     Average Validation Loss: 1.0558\n",
      "Train Epoch:  71 [  5559/5559 (100%)]\tLoss: 1.016853\n",
      "                     Average Validation Loss: 1.0551\n",
      "Train Epoch:  72 [  5559/5559 (100%)]\tLoss: 1.031762\n",
      "                     Average Validation Loss: 1.0542\n",
      "Train Epoch:  73 [  5559/5559 (100%)]\tLoss: 1.046202\n",
      "                     Average Validation Loss: 1.0532\n",
      "Train Epoch:  74 [  5559/5559 (100%)]\tLoss: 1.039916\n",
      "                     Average Validation Loss: 1.0511\n",
      "Train Epoch:  75 [  5559/5559 (100%)]\tLoss: 1.030301\n",
      "                     Average Validation Loss: 1.0507\n",
      "Train Epoch:  76 [  5559/5559 (100%)]\tLoss: 1.012758\n",
      "                     Average Validation Loss: 1.0501\n",
      "Train Epoch:  77 [  5559/5559 (100%)]\tLoss: 1.003007\n",
      "                     Average Validation Loss: 1.0488\n",
      "Train Epoch:  78 [  5559/5559 (100%)]\tLoss: 1.025288\n",
      "                     Average Validation Loss: 1.0467\n",
      "Train Epoch:  79 [  5559/5559 (100%)]\tLoss: 1.013577\n",
      "                     Average Validation Loss: 1.0462\n",
      "Train Epoch:  80 [  5559/5559 (100%)]\tLoss: 1.018110\n",
      "                     Average Validation Loss: 1.0448\n",
      "Train Epoch:  81 [  5559/5559 (100%)]\tLoss: 0.994509\n",
      "                     Average Validation Loss: 1.0450\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch:  82 [  5559/5559 (100%)]\tLoss: 1.023337\n",
      "                     Average Validation Loss: 1.0431\n",
      "Train Epoch:  83 [  5559/5559 (100%)]\tLoss: 1.003926\n",
      "                     Average Validation Loss: 1.0424\n",
      "Train Epoch:  84 [  5559/5559 (100%)]\tLoss: 1.014696\n",
      "                     Average Validation Loss: 1.0413\n",
      "Train Epoch:  85 [  5559/5559 (100%)]\tLoss: 1.002298\n",
      "                     Average Validation Loss: 1.0397\n",
      "Train Epoch:  86 [  5559/5559 (100%)]\tLoss: 1.026193\n",
      "                     Average Validation Loss: 1.0399\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch:  87 [  5559/5559 (100%)]\tLoss: 1.016790\n",
      "                     Average Validation Loss: 1.0384\n",
      "Train Epoch:  88 [  5559/5559 (100%)]\tLoss: 0.987207\n",
      "                     Average Validation Loss: 1.0374\n",
      "Train Epoch:  89 [  5559/5559 (100%)]\tLoss: 0.991267\n",
      "                     Average Validation Loss: 1.0370\n",
      "Train Epoch:  90 [  5559/5559 (100%)]\tLoss: 0.989015\n",
      "                     Average Validation Loss: 1.0366\n",
      "Train Epoch:  91 [  5559/5559 (100%)]\tLoss: 0.977711\n",
      "                     Average Validation Loss: 1.0353\n",
      "Train Epoch:  92 [  5559/5559 (100%)]\tLoss: 0.998768\n",
      "                     Average Validation Loss: 1.0353\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch:  93 [  5559/5559 (100%)]\tLoss: 1.011666\n",
      "                     Average Validation Loss: 1.0340\n",
      "Train Epoch:  94 [  5559/5559 (100%)]\tLoss: 1.001175\n",
      "                     Average Validation Loss: 1.0328\n",
      "Train Epoch:  95 [  5559/5559 (100%)]\tLoss: 1.011515\n",
      "                     Average Validation Loss: 1.0314\n",
      "Train Epoch:  96 [  5559/5559 (100%)]\tLoss: 0.993303\n",
      "                     Average Validation Loss: 1.0311\n",
      "Train Epoch:  97 [  5559/5559 (100%)]\tLoss: 1.005170\n",
      "                     Average Validation Loss: 1.0303\n",
      "Train Epoch:  98 [  5559/5559 (100%)]\tLoss: 0.990035\n",
      "                     Average Validation Loss: 1.0291\n",
      "Train Epoch:  99 [  5559/5559 (100%)]\tLoss: 1.002316\n",
      "                     Average Validation Loss: 1.0284\n",
      "Train Epoch: 100 [  5559/5559 (100%)]\tLoss: 0.995003\n",
      "                     Average Validation Loss: 1.0271\n",
      "Train Epoch: 101 [  5559/5559 (100%)]\tLoss: 0.981367\n",
      "                     Average Validation Loss: 1.0278\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 102 [  5559/5559 (100%)]\tLoss: 0.956696\n",
      "                     Average Validation Loss: 1.0267\n",
      "Train Epoch: 103 [  5559/5559 (100%)]\tLoss: 0.984634\n",
      "                     Average Validation Loss: 1.0253\n",
      "Train Epoch: 104 [  5559/5559 (100%)]\tLoss: 0.991025\n",
      "                     Average Validation Loss: 1.0247\n",
      "Train Epoch: 105 [  5559/5559 (100%)]\tLoss: 0.971770\n",
      "                     Average Validation Loss: 1.0239\n",
      "Train Epoch: 106 [  5559/5559 (100%)]\tLoss: 0.962685\n",
      "                     Average Validation Loss: 1.0238\n",
      "Train Epoch: 107 [  5559/5559 (100%)]\tLoss: 0.982778\n",
      "                     Average Validation Loss: 1.0227\n",
      "Train Epoch: 108 [  5559/5559 (100%)]\tLoss: 0.955036\n",
      "                     Average Validation Loss: 1.0226\n",
      "Train Epoch: 109 [  5559/5559 (100%)]\tLoss: 0.986081\n",
      "                     Average Validation Loss: 1.0214\n",
      "Train Epoch: 110 [  5559/5559 (100%)]\tLoss: 0.970585\n",
      "                     Average Validation Loss: 1.0209\n",
      "Train Epoch: 111 [  5559/5559 (100%)]\tLoss: 0.948608\n",
      "                     Average Validation Loss: 1.0194\n",
      "Train Epoch: 112 [  5559/5559 (100%)]\tLoss: 0.978110\n",
      "                     Average Validation Loss: 1.0194\n",
      "Train Epoch: 113 [  5559/5559 (100%)]\tLoss: 0.971766\n",
      "                     Average Validation Loss: 1.0190\n",
      "Train Epoch: 114 [  5559/5559 (100%)]\tLoss: 0.957500\n",
      "                     Average Validation Loss: 1.0195\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 115 [  5559/5559 (100%)]\tLoss: 0.942801\n",
      "                     Average Validation Loss: 1.0182\n",
      "Train Epoch: 116 [  5559/5559 (100%)]\tLoss: 0.991198\n",
      "                     Average Validation Loss: 1.0172\n",
      "Train Epoch: 117 [  5559/5559 (100%)]\tLoss: 0.953396\n",
      "                     Average Validation Loss: 1.0167\n",
      "Train Epoch: 118 [  5559/5559 (100%)]\tLoss: 0.964184\n",
      "                     Average Validation Loss: 1.0156\n",
      "Train Epoch: 119 [  5559/5559 (100%)]\tLoss: 0.978869\n",
      "                     Average Validation Loss: 1.0154\n",
      "Train Epoch: 120 [  5559/5559 (100%)]\tLoss: 0.982654\n",
      "                     Average Validation Loss: 1.0151\n",
      "Train Epoch: 121 [  5559/5559 (100%)]\tLoss: 0.954753\n",
      "                     Average Validation Loss: 1.0136\n",
      "Train Epoch: 122 [  5559/5559 (100%)]\tLoss: 0.930614\n",
      "                     Average Validation Loss: 1.0133\n",
      "Train Epoch: 123 [  5559/5559 (100%)]\tLoss: 0.965909\n",
      "                     Average Validation Loss: 1.0129\n",
      "Train Epoch: 124 [  5559/5559 (100%)]\tLoss: 0.967825\n",
      "                     Average Validation Loss: 1.0123\n",
      "Train Epoch: 125 [  5559/5559 (100%)]\tLoss: 0.939993\n",
      "                     Average Validation Loss: 1.0117\n",
      "Train Epoch: 126 [  5559/5559 (100%)]\tLoss: 0.946418\n",
      "                     Average Validation Loss: 1.0114\n",
      "Train Epoch: 127 [  5559/5559 (100%)]\tLoss: 0.924326\n",
      "                     Average Validation Loss: 1.0108\n",
      "Train Epoch: 128 [  5559/5559 (100%)]\tLoss: 0.975354\n",
      "                     Average Validation Loss: 1.0106\n",
      "Train Epoch: 129 [  5559/5559 (100%)]\tLoss: 0.981917\n",
      "                     Average Validation Loss: 1.0109\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 130 [  5559/5559 (100%)]\tLoss: 0.938014\n",
      "                     Average Validation Loss: 1.0099\n",
      "Train Epoch: 131 [  5559/5559 (100%)]\tLoss: 0.923129\n",
      "                     Average Validation Loss: 1.0094\n",
      "Train Epoch: 132 [  5559/5559 (100%)]\tLoss: 0.950598\n",
      "                     Average Validation Loss: 1.0084\n",
      "Train Epoch: 133 [  5559/5559 (100%)]\tLoss: 0.951768\n",
      "                     Average Validation Loss: 1.0082\n",
      "Train Epoch: 134 [  5559/5559 (100%)]\tLoss: 0.950547\n",
      "                     Average Validation Loss: 1.0075\n",
      "Train Epoch: 135 [  5559/5559 (100%)]\tLoss: 0.958148\n",
      "                     Average Validation Loss: 1.0068\n",
      "Train Epoch: 136 [  5559/5559 (100%)]\tLoss: 0.943630\n",
      "                     Average Validation Loss: 1.0063\n",
      "Train Epoch: 137 [  5559/5559 (100%)]\tLoss: 0.896131\n",
      "                     Average Validation Loss: 1.0060\n",
      "Train Epoch: 138 [  5559/5559 (100%)]\tLoss: 0.932426\n",
      "                     Average Validation Loss: 1.0049\n",
      "Train Epoch: 139 [  5559/5559 (100%)]\tLoss: 0.936616\n",
      "                     Average Validation Loss: 1.0046\n",
      "Train Epoch: 140 [  5559/5559 (100%)]\tLoss: 0.915147\n",
      "                     Average Validation Loss: 1.0034\n",
      "Train Epoch: 141 [  5559/5559 (100%)]\tLoss: 0.967445\n",
      "                     Average Validation Loss: 1.0037\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 142 [  5559/5559 (100%)]\tLoss: 0.946639\n",
      "                     Average Validation Loss: 1.0041\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 143 [  5559/5559 (100%)]\tLoss: 0.937907\n",
      "                     Average Validation Loss: 1.0029\n",
      "Train Epoch: 144 [  5559/5559 (100%)]\tLoss: 0.928762\n",
      "                     Average Validation Loss: 1.0031\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 145 [  5559/5559 (100%)]\tLoss: 0.918136\n",
      "                     Average Validation Loss: 1.0019\n",
      "Train Epoch: 146 [  5559/5559 (100%)]\tLoss: 0.909081\n",
      "                     Average Validation Loss: 1.0008\n",
      "Train Epoch: 147 [  5559/5559 (100%)]\tLoss: 0.919296\n",
      "                     Average Validation Loss: 1.0008\n",
      "Train Epoch: 148 [  5559/5559 (100%)]\tLoss: 0.934644\n",
      "                     Average Validation Loss: 1.0002\n",
      "Train Epoch: 149 [  5559/5559 (100%)]\tLoss: 0.906623\n",
      "                     Average Validation Loss: 1.0003\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 150 [  5559/5559 (100%)]\tLoss: 0.932387\n",
      "                     Average Validation Loss: 1.0001\n",
      "Train Epoch: 151 [  5559/5559 (100%)]\tLoss: 0.936608\n",
      "                     Average Validation Loss: 0.9997\n",
      "Train Epoch: 152 [  5559/5559 (100%)]\tLoss: 0.908271\n",
      "                     Average Validation Loss: 0.9988\n",
      "Train Epoch: 153 [  5559/5559 (100%)]\tLoss: 0.927480\n",
      "                     Average Validation Loss: 0.9987\n",
      "Train Epoch: 154 [  5559/5559 (100%)]\tLoss: 0.933223\n",
      "                     Average Validation Loss: 0.9986\n",
      "Train Epoch: 155 [  5559/5559 (100%)]\tLoss: 0.921543\n",
      "                     Average Validation Loss: 0.9977\n",
      "Train Epoch: 156 [  5559/5559 (100%)]\tLoss: 0.907103\n",
      "                     Average Validation Loss: 0.9968\n",
      "Train Epoch: 157 [  5559/5559 (100%)]\tLoss: 0.904477\n",
      "                     Average Validation Loss: 0.9965\n",
      "Train Epoch: 158 [  5559/5559 (100%)]\tLoss: 0.920730\n",
      "                     Average Validation Loss: 0.9965\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 159 [  5559/5559 (100%)]\tLoss: 0.930255\n",
      "                     Average Validation Loss: 0.9959\n",
      "Train Epoch: 160 [  5559/5559 (100%)]\tLoss: 0.903202\n",
      "                     Average Validation Loss: 0.9960\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 161 [  5559/5559 (100%)]\tLoss: 0.934710\n",
      "                     Average Validation Loss: 0.9946\n",
      "Train Epoch: 162 [  5559/5559 (100%)]\tLoss: 0.923638\n",
      "                     Average Validation Loss: 0.9950\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 163 [  5559/5559 (100%)]\tLoss: 0.924694\n",
      "                     Average Validation Loss: 0.9942\n",
      "Train Epoch: 164 [  5559/5559 (100%)]\tLoss: 0.911712\n",
      "                     Average Validation Loss: 0.9935\n",
      "Train Epoch: 165 [  5559/5559 (100%)]\tLoss: 0.930655\n",
      "                     Average Validation Loss: 0.9931\n",
      "Train Epoch: 166 [  5559/5559 (100%)]\tLoss: 0.898400\n",
      "                     Average Validation Loss: 0.9931\n",
      "Train Epoch: 167 [  5559/5559 (100%)]\tLoss: 0.904280\n",
      "                     Average Validation Loss: 0.9927\n",
      "Train Epoch: 168 [  5559/5559 (100%)]\tLoss: 0.932445\n",
      "                     Average Validation Loss: 0.9913\n",
      "Train Epoch: 169 [  5559/5559 (100%)]\tLoss: 0.913131\n",
      "                     Average Validation Loss: 0.9911\n",
      "Train Epoch: 170 [  5559/5559 (100%)]\tLoss: 0.901123\n",
      "                     Average Validation Loss: 0.9912\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 171 [  5559/5559 (100%)]\tLoss: 0.915088\n",
      "                     Average Validation Loss: 0.9907\n",
      "Train Epoch: 172 [  5559/5559 (100%)]\tLoss: 0.930905\n",
      "                     Average Validation Loss: 0.9899\n",
      "Train Epoch: 173 [  5559/5559 (100%)]\tLoss: 0.924006\n",
      "                     Average Validation Loss: 0.9900\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 174 [  5559/5559 (100%)]\tLoss: 0.920727\n",
      "                     Average Validation Loss: 0.9879\n",
      "Train Epoch: 175 [  5559/5559 (100%)]\tLoss: 0.924977\n",
      "                     Average Validation Loss: 0.9889\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 176 [  5559/5559 (100%)]\tLoss: 0.887719\n",
      "                     Average Validation Loss: 0.9894\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 177 [  5559/5559 (100%)]\tLoss: 0.887743\n",
      "                     Average Validation Loss: 0.9877\n",
      "Train Epoch: 178 [  5559/5559 (100%)]\tLoss: 0.926782\n",
      "                     Average Validation Loss: 0.9869\n",
      "Train Epoch: 179 [  5559/5559 (100%)]\tLoss: 0.935056\n",
      "                     Average Validation Loss: 0.9861\n",
      "Train Epoch: 180 [  5559/5559 (100%)]\tLoss: 0.892663\n",
      "                     Average Validation Loss: 0.9875\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 181 [  5559/5559 (100%)]\tLoss: 0.906399\n",
      "                     Average Validation Loss: 0.9875\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 182 [  5559/5559 (100%)]\tLoss: 0.901160\n",
      "                     Average Validation Loss: 0.9863\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 183 [  5559/5559 (100%)]\tLoss: 0.865152\n",
      "                     Average Validation Loss: 0.9865\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 184 [  5559/5559 (100%)]\tLoss: 0.926725\n",
      "                     Average Validation Loss: 0.9856\n",
      "Train Epoch: 185 [  5559/5559 (100%)]\tLoss: 0.876987\n",
      "                     Average Validation Loss: 0.9863\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 186 [  5559/5559 (100%)]\tLoss: 0.898354\n",
      "                     Average Validation Loss: 0.9849\n",
      "Train Epoch: 187 [  5559/5559 (100%)]\tLoss: 0.905875\n",
      "                     Average Validation Loss: 0.9851\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 188 [  5559/5559 (100%)]\tLoss: 0.889758\n",
      "                     Average Validation Loss: 0.9853\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 189 [  5559/5559 (100%)]\tLoss: 0.893905\n",
      "                     Average Validation Loss: 0.9856\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 190 [  5559/5559 (100%)]\tLoss: 0.933776\n",
      "                     Average Validation Loss: 0.9855\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 191 [  5559/5559 (100%)]\tLoss: 0.929456\n",
      "                     Average Validation Loss: 0.9845\n",
      "Train Epoch: 192 [  5559/5559 (100%)]\tLoss: 0.892369\n",
      "                     Average Validation Loss: 0.9845\n",
      "Train Epoch: 193 [  5559/5559 (100%)]\tLoss: 0.871616\n",
      "                     Average Validation Loss: 0.9839\n",
      "Train Epoch: 194 [  5559/5559 (100%)]\tLoss: 0.900073\n",
      "                     Average Validation Loss: 0.9839\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 195 [  5559/5559 (100%)]\tLoss: 0.903438\n",
      "                     Average Validation Loss: 0.9845\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 196 [  5559/5559 (100%)]\tLoss: 0.912955\n",
      "                     Average Validation Loss: 0.9847\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 197 [  5559/5559 (100%)]\tLoss: 0.881578\n",
      "                     Average Validation Loss: 0.9838\n",
      "Train Epoch: 198 [  5559/5559 (100%)]\tLoss: 0.927212\n",
      "                     Average Validation Loss: 0.9846\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 199 [  5559/5559 (100%)]\tLoss: 0.906792\n",
      "                     Average Validation Loss: 0.9840\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 200 [  5559/5559 (100%)]\tLoss: 0.888504\n",
      "                     Average Validation Loss: 0.9834\n",
      "Train Epoch: 201 [  5559/5559 (100%)]\tLoss: 0.876915\n",
      "                     Average Validation Loss: 0.9837\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 202 [  5559/5559 (100%)]\tLoss: 0.871620\n",
      "                     Average Validation Loss: 0.9830\n",
      "Train Epoch: 203 [  5559/5559 (100%)]\tLoss: 0.876460\n",
      "                     Average Validation Loss: 0.9824\n",
      "Train Epoch: 204 [  5559/5559 (100%)]\tLoss: 0.870013\n",
      "                     Average Validation Loss: 0.9831\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 205 [  5559/5559 (100%)]\tLoss: 0.881563\n",
      "                     Average Validation Loss: 0.9828\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 206 [  5559/5559 (100%)]\tLoss: 0.900233\n",
      "                     Average Validation Loss: 0.9831\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 207 [  5559/5559 (100%)]\tLoss: 0.920987\n",
      "                     Average Validation Loss: 0.9829\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 208 [  5559/5559 (100%)]\tLoss: 0.889181\n",
      "                     Average Validation Loss: 0.9830\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 209 [  5559/5559 (100%)]\tLoss: 0.963491\n",
      "                     Average Validation Loss: 0.9823\n",
      "Train Epoch: 210 [  5559/5559 (100%)]\tLoss: 0.888610\n",
      "                     Average Validation Loss: 0.9827\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 211 [  5559/5559 (100%)]\tLoss: 0.900817\n",
      "                     Average Validation Loss: 0.9825\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 212 [  5559/5559 (100%)]\tLoss: 0.893178\n",
      "                     Average Validation Loss: 0.9826\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 213 [  5559/5559 (100%)]\tLoss: 0.875233\n",
      "                     Average Validation Loss: 0.9827\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 214 [  5559/5559 (100%)]\tLoss: 0.870369\n",
      "                     Average Validation Loss: 0.9824\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 215 [  5559/5559 (100%)]\tLoss: 0.881409\n",
      "                     Average Validation Loss: 0.9829\n",
      "        Early Stopping count: 6/30\n",
      "Train Epoch: 216 [  5559/5559 (100%)]\tLoss: 0.896476\n",
      "                     Average Validation Loss: 0.9830\n",
      "        Early Stopping count: 7/30\n",
      "Train Epoch: 217 [  5559/5559 (100%)]\tLoss: 0.913061\n",
      "                     Average Validation Loss: 0.9827\n",
      "        Early Stopping count: 8/30\n",
      "Train Epoch: 218 [  5559/5559 (100%)]\tLoss: 0.927434\n",
      "                     Average Validation Loss: 0.9820\n",
      "Train Epoch: 219 [  5559/5559 (100%)]\tLoss: 0.890325\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 220 [  5559/5559 (100%)]\tLoss: 0.903626\n",
      "                     Average Validation Loss: 0.9828\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 221 [  5559/5559 (100%)]\tLoss: 0.901271\n",
      "                     Average Validation Loss: 0.9828\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 222 [  5559/5559 (100%)]\tLoss: 0.906735\n",
      "                     Average Validation Loss: 0.9816\n",
      "Train Epoch: 223 [  5559/5559 (100%)]\tLoss: 0.898864\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 224 [  5559/5559 (100%)]\tLoss: 0.865484\n",
      "                     Average Validation Loss: 0.9823\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 225 [  5559/5559 (100%)]\tLoss: 0.894982\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 226 [  5559/5559 (100%)]\tLoss: 0.874215\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 227 [  5559/5559 (100%)]\tLoss: 0.921565\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 228 [  5559/5559 (100%)]\tLoss: 0.860620\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 6/30\n",
      "Train Epoch: 229 [  5559/5559 (100%)]\tLoss: 0.915371\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 7/30\n",
      "Train Epoch: 230 [  5559/5559 (100%)]\tLoss: 0.874964\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 8/30\n",
      "Train Epoch: 231 [  5559/5559 (100%)]\tLoss: 0.891316\n",
      "                     Average Validation Loss: 0.9813\n",
      "Train Epoch: 232 [  5559/5559 (100%)]\tLoss: 0.925137\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 233 [  5559/5559 (100%)]\tLoss: 0.888027\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 234 [  5559/5559 (100%)]\tLoss: 0.924581\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 235 [  5559/5559 (100%)]\tLoss: 0.861390\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 236 [  5559/5559 (100%)]\tLoss: 0.880336\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 237 [  5559/5559 (100%)]\tLoss: 0.859374\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 6/30\n",
      "Train Epoch: 238 [  5559/5559 (100%)]\tLoss: 0.903662\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 7/30\n",
      "Train Epoch: 239 [  5559/5559 (100%)]\tLoss: 0.896005\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 8/30\n",
      "Train Epoch: 240 [  5559/5559 (100%)]\tLoss: 0.877442\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 9/30\n",
      "Train Epoch: 241 [  5559/5559 (100%)]\tLoss: 0.898556\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 10/30\n",
      "Train Epoch: 242 [  5559/5559 (100%)]\tLoss: 0.924682\n",
      "                     Average Validation Loss: 0.9814\n",
      "        Early Stopping count: 11/30\n",
      "Train Epoch: 243 [  5559/5559 (100%)]\tLoss: 0.873569\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 12/30\n",
      "Train Epoch: 244 [  5559/5559 (100%)]\tLoss: 0.879634\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 13/30\n",
      "Train Epoch: 245 [  5559/5559 (100%)]\tLoss: 0.857876\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 14/30\n",
      "Train Epoch: 246 [  5559/5559 (100%)]\tLoss: 0.864966\n",
      "                     Average Validation Loss: 0.9823\n",
      "        Early Stopping count: 15/30\n",
      "Train Epoch: 247 [  5559/5559 (100%)]\tLoss: 0.880748\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 16/30\n",
      "Train Epoch: 248 [  5559/5559 (100%)]\tLoss: 0.868001\n",
      "                     Average Validation Loss: 0.9814\n",
      "        Early Stopping count: 17/30\n",
      "Train Epoch: 249 [  5559/5559 (100%)]\tLoss: 0.905827\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 18/30\n",
      "Train Epoch: 250 [  5559/5559 (100%)]\tLoss: 0.896573\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 19/30\n",
      "Train Epoch: 251 [  5559/5559 (100%)]\tLoss: 0.910183\n",
      "                     Average Validation Loss: 0.9818\n",
      "        Early Stopping count: 20/30\n",
      "Train Epoch: 252 [  5559/5559 (100%)]\tLoss: 0.885813\n",
      "                     Average Validation Loss: 0.9824\n",
      "        Early Stopping count: 21/30\n",
      "Train Epoch: 253 [  5559/5559 (100%)]\tLoss: 0.897043\n",
      "                     Average Validation Loss: 0.9824\n",
      "        Early Stopping count: 22/30\n",
      "Train Epoch: 254 [  5559/5559 (100%)]\tLoss: 0.884876\n",
      "                     Average Validation Loss: 0.9823\n",
      "        Early Stopping count: 23/30\n",
      "Train Epoch: 255 [  5559/5559 (100%)]\tLoss: 0.899260\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 24/30\n",
      "Train Epoch: 256 [  5559/5559 (100%)]\tLoss: 0.874105\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 25/30\n",
      "Train Epoch: 257 [  5559/5559 (100%)]\tLoss: 0.870354\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 26/30\n",
      "Train Epoch: 258 [  5559/5559 (100%)]\tLoss: 0.906694\n",
      "                     Average Validation Loss: 0.9827\n",
      "        Early Stopping count: 27/30\n",
      "Train Epoch: 259 [  5559/5559 (100%)]\tLoss: 0.897009\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 28/30\n",
      "Train Epoch: 260 [  5559/5559 (100%)]\tLoss: 0.879484\n",
      "                     Average Validation Loss: 0.9813\n",
      "Train Epoch: 261 [  5559/5559 (100%)]\tLoss: 0.888058\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 262 [  5559/5559 (100%)]\tLoss: 0.922983\n",
      "                     Average Validation Loss: 0.9818\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 263 [  5559/5559 (100%)]\tLoss: 0.872334\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 264 [  5559/5559 (100%)]\tLoss: 0.874613\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 265 [  5559/5559 (100%)]\tLoss: 0.874507\n",
      "                     Average Validation Loss: 0.9816\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 266 [  5559/5559 (100%)]\tLoss: 0.879519\n",
      "                     Average Validation Loss: 0.9810\n",
      "Train Epoch: 267 [  5559/5559 (100%)]\tLoss: 0.892563\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 1/30\n",
      "Train Epoch: 268 [  5559/5559 (100%)]\tLoss: 0.882540\n",
      "                     Average Validation Loss: 0.9816\n",
      "        Early Stopping count: 2/30\n",
      "Train Epoch: 269 [  5559/5559 (100%)]\tLoss: 0.923862\n",
      "                     Average Validation Loss: 0.9823\n",
      "        Early Stopping count: 3/30\n",
      "Train Epoch: 270 [  5559/5559 (100%)]\tLoss: 0.882833\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 4/30\n",
      "Train Epoch: 271 [  5559/5559 (100%)]\tLoss: 0.885500\n",
      "                     Average Validation Loss: 0.9818\n",
      "        Early Stopping count: 5/30\n",
      "Train Epoch: 272 [  5559/5559 (100%)]\tLoss: 0.933358\n",
      "                     Average Validation Loss: 0.9816\n",
      "        Early Stopping count: 6/30\n",
      "Train Epoch: 273 [  5559/5559 (100%)]\tLoss: 0.910821\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 7/30\n",
      "Train Epoch: 274 [  5559/5559 (100%)]\tLoss: 0.877128\n",
      "                     Average Validation Loss: 0.9813\n",
      "        Early Stopping count: 8/30\n",
      "Train Epoch: 275 [  5559/5559 (100%)]\tLoss: 0.886290\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 9/30\n",
      "Train Epoch: 276 [  5559/5559 (100%)]\tLoss: 0.883058\n",
      "                     Average Validation Loss: 0.9825\n",
      "        Early Stopping count: 10/30\n",
      "Train Epoch: 277 [  5559/5559 (100%)]\tLoss: 0.907683\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 11/30\n",
      "Train Epoch: 278 [  5559/5559 (100%)]\tLoss: 0.864115\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 12/30\n",
      "Train Epoch: 279 [  5559/5559 (100%)]\tLoss: 0.909826\n",
      "                     Average Validation Loss: 0.9820\n",
      "        Early Stopping count: 13/30\n",
      "Train Epoch: 280 [  5559/5559 (100%)]\tLoss: 0.873914\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 14/30\n",
      "Train Epoch: 281 [  5559/5559 (100%)]\tLoss: 0.898369\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 15/30\n",
      "Train Epoch: 282 [  5559/5559 (100%)]\tLoss: 0.880344\n",
      "                     Average Validation Loss: 0.9822\n",
      "        Early Stopping count: 16/30\n",
      "Train Epoch: 283 [  5559/5559 (100%)]\tLoss: 0.892781\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 17/30\n",
      "Train Epoch: 284 [  5559/5559 (100%)]\tLoss: 0.895339\n",
      "                     Average Validation Loss: 0.9814\n",
      "        Early Stopping count: 18/30\n",
      "Train Epoch: 285 [  5559/5559 (100%)]\tLoss: 0.869844\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 19/30\n",
      "Train Epoch: 286 [  5559/5559 (100%)]\tLoss: 0.886461\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 20/30\n",
      "Train Epoch: 287 [  5559/5559 (100%)]\tLoss: 0.881277\n",
      "                     Average Validation Loss: 0.9818\n",
      "        Early Stopping count: 21/30\n",
      "Train Epoch: 288 [  5559/5559 (100%)]\tLoss: 0.909641\n",
      "                     Average Validation Loss: 0.9813\n",
      "        Early Stopping count: 22/30\n",
      "Train Epoch: 289 [  5559/5559 (100%)]\tLoss: 0.880913\n",
      "                     Average Validation Loss: 0.9815\n",
      "        Early Stopping count: 23/30\n",
      "Train Epoch: 290 [  5559/5559 (100%)]\tLoss: 0.898405\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 24/30\n",
      "Train Epoch: 291 [  5559/5559 (100%)]\tLoss: 0.897251\n",
      "                     Average Validation Loss: 0.9819\n",
      "        Early Stopping count: 25/30\n",
      "Train Epoch: 292 [  5559/5559 (100%)]\tLoss: 0.878256\n",
      "                     Average Validation Loss: 0.9821\n",
      "        Early Stopping count: 26/30\n",
      "Train Epoch: 293 [  5559/5559 (100%)]\tLoss: 0.891947\n",
      "                     Average Validation Loss: 0.9816\n",
      "        Early Stopping count: 27/30\n",
      "Train Epoch: 294 [  5559/5559 (100%)]\tLoss: 0.890916\n",
      "                     Average Validation Loss: 0.9813\n",
      "        Early Stopping count: 28/30\n",
      "Train Epoch: 295 [  5559/5559 (100%)]\tLoss: 0.895100\n",
      "                     Average Validation Loss: 0.9818\n",
      "        Early Stopping count: 29/30\n",
      "Train Epoch: 296 [  5559/5559 (100%)]\tLoss: 0.906507\n",
      "                     Average Validation Loss: 0.9817\n",
      "        Early Stopping count: 30/30\n",
      "\n",
      "Early Stopping. Best Epoch: 266 with loss 0.9810.\n",
      "\n",
      "Final Performance!\n",
      "\n",
      "                     Average Training Loss: 0.9285\n",
      "\n",
      "                     Average Validation Loss: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Create Datasets\n",
    "np.random.seed(42)\n",
    "mycat = cat.sample(frac=1)\n",
    "train_loader = DataLoader(WaveletDataset(mycat, \"train\"), batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(WaveletDataset(mycat, \"val\"), batch_size=BATCH_SIZE)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = ConvNet(channels[RUN_NUMBER], k=3).to(device)\n",
    "\n",
    "# Training\n",
    "weights, train_losses, val_losses = train(model, device, train_loader, val_loader, PATIENCE, MAX_EPOCHS, MODEL_NAME)\n",
    "\n",
    "# Evaluate best-fit model\n",
    "model.load_state_dict(weights)\n",
    "print(\"\\nFinal Performance!\")\n",
    "test(model, device, train_loader, mode=\"Training\")\n",
    "test(model, device, val_loader, mode=\"Validation\")\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss', alpha=0.5)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{MODEL_NAME}/plots/{MODEL_NAME}_performance.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32ab3f3-e238-493a-8278-016fdfa1893a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T17:19:42.229635Z",
     "iopub.status.busy": "2024-12-16T17:19:42.229153Z",
     "iopub.status.idle": "2024-12-16T17:19:43.019958Z",
     "shell.execute_reply": "2024-12-16T17:19:43.019537Z",
     "shell.execute_reply.started": "2024-12-16T17:19:42.229616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction on Test set\n",
      "\n",
      "                     Average Test Loss: 0.9887\n"
     ]
    }
   ],
   "source": [
    "# Predictions on Test set\n",
    "print('\\nPrediction on Test set')\n",
    "test_loader = DataLoader(WaveletDataset(mycat, \"test\"), batch_size=BATCH_SIZE)\n",
    "preds, labels, loss = test(model, device, test_loader, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f1e203-cc08-4855-a5f7-65851cc12dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T17:19:49.185755Z",
     "iopub.status.busy": "2024-12-16T17:19:49.185347Z",
     "iopub.status.idle": "2024-12-16T17:19:49.211300Z",
     "shell.execute_reply": "2024-12-16T17:19:49.210879Z",
     "shell.execute_reply.started": "2024-12-16T17:19:49.185737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ebs_true</th>\n",
       "      <th>exo_true</th>\n",
       "      <th>flares_true</th>\n",
       "      <th>rot_true</th>\n",
       "      <th>ebs_pred</th>\n",
       "      <th>exo_pred</th>\n",
       "      <th>flares_pred</th>\n",
       "      <th>rot_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIC</th>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366972961</th>\n",
       "      <th>25</th>\n",
       "      <td>tess2020133194932-s0025-0000000366972961-0182-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349156098</th>\n",
       "      <th>31</th>\n",
       "      <td>tess2020294194027-s0031-0000000349156098-0198-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890435</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139804406</th>\n",
       "      <th>1</th>\n",
       "      <td>tess2018206045859-s0001-0000000139804406-0120-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.926536</td>\n",
       "      <td>0.060204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237913194</th>\n",
       "      <th>28</th>\n",
       "      <td>tess2020212050318-s0028-0000000237913194-0190-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.993885</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238123653</th>\n",
       "      <th>7</th>\n",
       "      <td>tess2019006130736-s0007-0000000238123653-0131-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.940781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264461976</th>\n",
       "      <th>32</th>\n",
       "      <td>tess2020324010417-s0032-0000000264461976-0200-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166463</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.790926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339960875</th>\n",
       "      <th>7</th>\n",
       "      <td>tess2019006130736-s0007-0000000339960875-0131-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>0.958926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343173162</th>\n",
       "      <th>24</th>\n",
       "      <td>tess2020106103520-s0024-0000000343173162-0180-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.997703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350073391</th>\n",
       "      <th>26</th>\n",
       "      <td>tess2020160202036-s0026-0000000350073391-0188-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.966161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59843967</th>\n",
       "      <th>6</th>\n",
       "      <td>tess2018349182500-s0006-0000000059843967-0126-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.968988</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           filename  ebs_true  \\\n",
       "TIC       sector                                                                \n",
       "366972961 25      tess2020133194932-s0025-0000000366972961-0182-...       1.0   \n",
       "349156098 31      tess2020294194027-s0031-0000000349156098-0198-...       1.0   \n",
       "139804406 1       tess2018206045859-s0001-0000000139804406-0120-...       0.0   \n",
       "237913194 28      tess2020212050318-s0028-0000000237913194-0190-...       0.0   \n",
       "238123653 7       tess2019006130736-s0007-0000000238123653-0131-...       0.0   \n",
       "...                                                             ...       ...   \n",
       "264461976 32      tess2020324010417-s0032-0000000264461976-0200-...       0.0   \n",
       "339960875 7       tess2019006130736-s0007-0000000339960875-0131-...       0.0   \n",
       "343173162 24      tess2020106103520-s0024-0000000343173162-0180-...       0.0   \n",
       "350073391 26      tess2020160202036-s0026-0000000350073391-0188-...       0.0   \n",
       "59843967  6       tess2018349182500-s0006-0000000059843967-0126-...       0.0   \n",
       "\n",
       "                  exo_true  flares_true  rot_true  ebs_pred  exo_pred  \\\n",
       "TIC       sector                                                        \n",
       "366972961 25           0.0          0.0       0.0  0.992689  0.004412   \n",
       "349156098 31           0.0          0.0       0.0  0.890435  0.087259   \n",
       "139804406 1            0.0          1.0       0.0  0.007339  0.005922   \n",
       "237913194 28           1.0          0.0       0.0  0.004000  0.993885   \n",
       "238123653 7            0.0          0.0       1.0  0.008049  0.006662   \n",
       "...                    ...          ...       ...       ...       ...   \n",
       "264461976 32           0.0          0.0       1.0  0.166463  0.006412   \n",
       "339960875 7            0.0          0.0       1.0  0.009004  0.001515   \n",
       "343173162 24           0.0          0.0       1.0  0.000272  0.000790   \n",
       "350073391 26           0.0          0.0       1.0  0.008206  0.006810   \n",
       "59843967  6            1.0          0.0       0.0  0.024648  0.968988   \n",
       "\n",
       "                  flares_pred  rot_pred  \n",
       "TIC       sector                         \n",
       "366972961 25         0.001550  0.001349  \n",
       "349156098 31         0.013445  0.008861  \n",
       "139804406 1          0.926536  0.060204  \n",
       "237913194 28         0.001446  0.000668  \n",
       "238123653 7          0.044507  0.940781  \n",
       "...                       ...       ...  \n",
       "264461976 32         0.036199  0.790926  \n",
       "339960875 7          0.030555  0.958926  \n",
       "343173162 24         0.001234  0.997703  \n",
       "350073391 26         0.018824  0.966161  \n",
       "59843967  6          0.003571  0.002793  \n",
       "\n",
       "[695 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = mycat.iloc[-len(labels):].drop(columns=\"wavelet\")\n",
    "output = output.rename(columns={c: c+\"_true\" for c in cols})\n",
    "output[[c+\"_pred\" for c in cols]] = preds\n",
    "output.to_csv(f\"{MODEL_NAME}/output/{MODEL_NAME}_output.csv\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b1e0d-e18b-4c4c-92eb-b7f8ff67622a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
